# titanic_train.py
# Usage:
# 1) put train.csv in data/
# 2) python titanic_train.py
# Output: prints evaluation and saves best_model.pkl

import pandas as pd
import numpy as np
import pickle
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, roc_auc_score, roc_curve

def load_data(path="data/train.csv"):
    df = pd.read_csv(path)
    return df

def feature_engineer(df):
    df = df.copy()
    # Title from Name
    df['Title'] = df['Name'].str.extract(r',\s*([^\.]+)\.')
    rare_titles = (df['Title'].value_counts() < 10)
    df['Title'] = df['Title'].apply(lambda t: 'Rare' if rare_titles.get(t, False) else t)
    # Family size
    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1
    # IsAlone
    df['IsAlone'] = (df['FamilySize'] == 1).astype(int)
    # Fill cabin with deck letter
    df['Deck'] = df['Cabin'].fillna('Unknown').str[0]
    # Drop columns we won't use
    df = df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)
    return df

def build_pipeline():
    numeric_features = ['Age', 'Fare', 'FamilySize']
    numeric_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='median'))
    ])

    categorical_features = ['Pclass', 'Sex', 'Embarked', 'Title', 'Deck', 'IsAlone']
    categorical_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='most_frequent')),
        ('onehot', OneHotEncoder(handle_unknown='ignore'))
    ])

    preprocessor = ColumnTransformer(transformers=[
        ('num', numeric_transformer, numeric_features),
        ('cat', categorical_transformer, categorical_features)
    ])
    return preprocessor

def main():
    df = load_data()
    df = feature_engineer(df)
    X = df.drop('Survived', axis=1)
    y = df['Survived']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

    preprocessor = build_pipeline()

    # Two models to try
    rf = Pipeline(steps=[('pre', preprocessor),
                         ('clf', RandomForestClassifier(random_state=42))])
    lr = Pipeline(steps=[('pre', preprocessor),
                         ('clf', LogisticRegression(max_iter=1000))])

    # Quick grid for RF
    param_grid = {
        'clf__n_estimators': [100, 200],
        'clf__max_depth': [5, 10, None]
    }

    grid = GridSearchCV(rf, param_grid=param_grid, cv=5, scoring='roc_auc', n_jobs=-1)
    grid.fit(X_train, y_train)
    best = grid.best_estimator_
    print("Best RF params:", grid.best_params_)

    # Evaluate
    y_pred = best.predict(X_test)
    y_proba = best.predict_proba(X_test)[:, 1]
    print("Classification report (RandomForest):")
    print(classification_report(y_test, y_pred))
    print("ROC-AUC:", roc_auc_score(y_test, y_proba))

    # Also try logistic regression baseline
    lr.fit(X_train, y_train)
    y_pred_lr = lr.predict(X_test)
    y_proba_lr = lr.predict_proba(X_test)[:,1]
    print("Classification report (LogisticRegression):")
    print(classification_report(y_test, y_pred_lr))
    print("ROC-AUC (LR):", roc_auc_score(y_test, y_proba_lr))

    # Save best model
    with open('best_model.pkl', 'wb') as f:
        pickle.dump(best, f)
    print("Saved best_model.pkl")

if __name__ == "__main__":
    main()
